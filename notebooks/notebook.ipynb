{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cc2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PCAM Baseline Model Training Notebook\n",
    "This script loads the PCAM dataset, builds a simple ResNet50 model, and trains it for binary classification.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # For visualization\n",
    "from collections import Counter\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e87e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ============ CONFIGURATION ============\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "SUBSET_SIZE = 10000  # Use 10k samples for quick iteration\n",
    "DATA_ROOT = './data'\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c446f03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING PCAM DATASET FOR VISUALISATION\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "FileURLRetrievalError",
     "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1Ka0XfEMiwgCYPdTI-vv6eUElOBnKFKQ2\n\nbut Gdown can't. Please check connections and permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning/ML/ml-pipeline-cv/.venv/lib/python3.13/site-packages/gdown/download.py:267\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     url = \u001b[43mget_url_from_gdrive_confirmation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning/ML/ml-pipeline-cv/.venv/lib/python3.13/site-packages/gdown/download.py:53\u001b[39m, in \u001b[36mget_url_from_gdrive_confirmation\u001b[39m\u001b[34m(contents)\u001b[39m\n\u001b[32m     52\u001b[39m         error = m.groups()[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(error)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load datasets without transforms first (just for analysis)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m train_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPCAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m val_dataset = datasets.PCAM(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, split=\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m, download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     10\u001b[39m test_dataset = datasets.PCAM(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, split=\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m, download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning/ML/ml-pipeline-cv/.venv/lib/python3.13/site-packages/torchvision/datasets/pcam.py:96\u001b[39m, in \u001b[36mPCAM.__init__\u001b[39m\u001b[34m(self, root, split, transform, target_transform, download)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28mself\u001b[39m._base_folder = pathlib.Path(\u001b[38;5;28mself\u001b[39m.root) / \u001b[33m\"\u001b[39m\u001b[33mpcam\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning/ML/ml-pipeline-cv/.venv/lib/python3.13/site-packages/torchvision/datasets/pcam.py:133\u001b[39m, in \u001b[36mPCAM._download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_name, file_id, md5 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._FILES[\u001b[38;5;28mself\u001b[39m._split].values():\n\u001b[32m    132\u001b[39m     archive_name = file_name + \u001b[33m\"\u001b[39m\u001b[33m.gz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[43mdownload_file_from_google_drive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_base_folder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43marchive_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     _decompress(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._base_folder / archive_name))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning/ML/ml-pipeline-cv/.venv/lib/python3.13/site-packages/torchvision/datasets/utils.py:203\u001b[39m, in \u001b[36mdownload_file_from_google_drive\u001b[39m\u001b[34m(file_id, root, filename, md5)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_integrity(fpath, md5):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[43mgdown\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSER_AGENT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile not found or corrupted.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning/ML/ml-pipeline-cv/.venv/lib/python3.13/site-packages/gdown/download.py:278\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    269\u001b[39m         message = (\n\u001b[32m    270\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve file url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    271\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou may still be able to access the file from the browser:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    276\u001b[39m             url_origin,\n\u001b[32m    277\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(message)\n\u001b[32m    280\u001b[39m filename_from_url = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    281\u001b[39m last_modified_time = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1Ka0XfEMiwgCYPdTI-vv6eUElOBnKFKQ2\n\nbut Gdown can't. Please check connections and permissions."
     ]
    }
   ],
   "source": [
    "# ============ DATA LOADING AND ANALYSIS ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING PCAM DATASET FOR VISUALISATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# Load datasets without transforms first (just for analysis)\n",
    "train_dataset = datasets.PCAM(root='./data', split='train', download=True, transform=None)\n",
    "val_dataset = datasets.PCAM(root='./data', split='val', download=True, transform=None)\n",
    "test_dataset = datasets.PCAM(root='./data', split='test', download=True, transform=None)\n",
    "\n",
    "print(f\"Full dataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset)}\")\n",
    "print(f\"  Val: {len(val_dataset)}\")\n",
    "print(f\"  Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab46474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single sample to check structure\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "print(f\"\\nSingle Sample Structure:\")\n",
    "print(f\"  Image type: {type(sample_image)}\")\n",
    "print(f\"  Image shape: {sample_image.size if hasattr(sample_image, 'size') else np.array(sample_image).shape}\")\n",
    "print(f\"  Image value range: min={np.array(sample_image).min()}, max={np.array(sample_image).max()}\")\n",
    "print(f\"  Label: {sample_label} (type: {type(sample_label)})\")\n",
    "\n",
    "# Visualize a few samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx in range(6):\n",
    "    image, label = train_dataset[idx]\n",
    "    axes[idx].imshow(np.array(image))\n",
    "    axes[idx].set_title(f\"Label: {label}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pcam_samples.png')\n",
    "print(f\"\\nSample visualization saved as 'pcam_samples.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f09b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ DATA LOADING AND ANALYSIS ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING PCAM DATASET WITH TRANSFORMATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),           # Convert to PyTorch Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize\n",
    "])\n",
    "\n",
    "# Load datasets without transforms first (just for analysis)\n",
    "train_dataset = datasets.PCAM(root='./data', split='train', download=True, transform=transform)\n",
    "val_dataset = datasets.PCAM(root='./data', split='val', download=True, transform=transform)\n",
    "test_dataset = datasets.PCAM(root='./data', split='test', download=True, transform=transform)\n",
    "\n",
    "print(f\"Full dataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset)}\")\n",
    "print(f\"  Val: {len(val_dataset)}\")\n",
    "print(f\"  Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(f\"\\nClass Distribution:\")\n",
    "\n",
    "train_labels = [train_dataset[i][1] for i in range(len(train_dataset))]\n",
    "val_labels = [val_dataset[i][1] for i in range(len(val_dataset))]\n",
    "test_labels = [test_dataset[i][1] for i in range(len(test_dataset))]\n",
    "\n",
    "train_counts = Counter(train_labels)\n",
    "val_counts = Counter(val_labels)\n",
    "test_counts = Counter(test_labels)\n",
    "\n",
    "print(f\"  Train - Class 0: {train_counts[0]}, Class 1: {train_counts[1]}\")\n",
    "print(f\"  Val - Class 0: {val_counts[0]}, Class 1: {val_counts[1]}\")\n",
    "print(f\"  Test - Class 0: {test_counts[0]}, Class 1: {test_counts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840145f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset for faster iteration\n",
    "subset_indices = torch.randperm(len(train_dataset))[:SUBSET_SIZE].tolist()\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "# Create proportional val subset\n",
    "val_subset_size = int(SUBSET_SIZE * 0.2)\n",
    "val_indices = torch.randperm(len(val_dataset))[:val_subset_size].tolist()\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "\n",
    "print(f\"\\nSubset sizes (for training):\")\n",
    "print(f\"  Train subset: {len(train_subset)}\")\n",
    "print(f\"  Val subset: {len(val_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea053fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Verify data loading\n",
    "batch_images, batch_labels = next(iter(train_loader))\n",
    "print(f\"\\nBatch verification:\")\n",
    "print(f\"  Batch images shape: {batch_images.shape}\")\n",
    "print(f\"  Batch labels shape: {batch_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dceab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCamModel(nn.Module):\n",
    "    def __init__(self, num_classes=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        self.num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(self.num_ftrs, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    \n",
    "model = PCamModel(num_classes=2, pretrained=False)\n",
    "print(f\"Model created: ResNet50 with {model.num_classes} output classes\")\n",
    "\n",
    "# Test forward pass\n",
    "test_output = model(batch_images)\n",
    "print(f\"Test forward pass output shape: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ TRAINING ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Train the model with validation after each epoch\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_accuracy)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_accuracy)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "trained_model, training_history = train_model(model, train_loader, val_loader, NUM_EPOCHS, DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ EVALUATION ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "test_accuracy = evaluate_model(trained_model, test_loader, DEVICE)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c124b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============ SAVE MODEL ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "torch.save(trained_model.state_dict(), 'pcam_baseline_model.pth')\n",
    "print(\"Model saved as 'pcam_baseline_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ VISUALIZATION ============\n",
    "print(\"\\nGenerating training history plots...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(training_history['train_loss'], label='Train Loss')\n",
    "ax1.plot(training_history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "ax2.plot(training_history['train_acc'], label='Train Acc')\n",
    "ax2.plot(training_history['val_acc'], label='Val Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=100)\n",
    "print(\"Training history plot saved as 'training_history.png'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
